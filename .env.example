# 模型提供商选择
# 可选值: openai, azure, custom, qwen
MODEL_PROVIDER=custom

# DeepSeek API配置 (与OpenAI API兼容)
OPENAI_API_KEY=sk-9ceeb7a2324c461d9f8a45a6c95b13b5
OPENAI_API_BASE=https://api.deepseek.com/v1

# 如果使用Azure OpenAI，请配置以下选项并将MODEL_PROVIDER设置为azure
# AZURE_OPENAI_API_KEY=your_azure_openai_api_key
# AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint
# AZURE_OPENAI_DEPLOYMENT_NAME=your_deployment_name

# 如果使用其他OpenAI兼容的API，请配置以下选项并将MODEL_PROVIDER设置为custom
# OPENAI_API_BASE=https://your-api-endpoint.com/v1

# 如果使用阿里云Qwen模型，请配置以下选项并将MODEL_PROVIDER设置为qwen
# QWEN_API_KEY=your_qwen_api_key
# ALIYUN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# QWEN3_MAX=qwen3-max

# 服务配置
HOST=0.0.0.0
PORT=8000
BACKEND_SERVICE_URL=http://localhost:8002
DEBUG=True

# LangChain配置（可选，用于跟踪和调试）
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langchain_api_key
LANGCHAIN_PROJECT=your_project_name

# 模型配置
# DeepSeek可用模型: deepseek-chat, deepseek-coder
MODEL_NAME=deepseek-chat
MODEL_TEMPERATURE=0.7