# AI驱动的接口自动化测试工具后端服务实现方案

## 项目概述

本方案旨在构建一个后端服务，用于实现将手工测试用例转换为接口自动化测试脚本的功能。服务将基于LangChain框架，利用大语言模型处理自然语言描述的测试用例，并生成相应的自动化测试脚本。

## 技术架构

### 后端技术栈

- **编程语言**: Python 3.8+
- **Web框架**: FastAPI
- **AI框架**: LangChain
- **大语言模型**: OpenAI GPT 或其他兼容模型
- **测试框架**: pytest
- **依赖管理**: pipenv 或 poetry

### 服务架构设计

```
┌─────────────────────────────────────────────────────────────┐
│                    Client Request                           │
└─────────────────────────┬───────────────────────────────────┘
                          │
┌─────────────────────────▼───────────────────────────────────┐
│                    FastAPI Router                           │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────────┐   │
│  │ POST /convert│  │ GET /status  │  │ GET /test-cases  │   │
│  └──────────────┘  └──────────────┘  └──────────────────┘   │
└─────────────────────────┬───────────────────────────────────┘
                          │
┌─────────────────────────▼───────────────────────────────────┐
│                   Service Layer                             │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │           Test Case Conversion Service                 │ │
│  │                                                         │ │
│  │  ┌─────────────────┐  ┌─────────────────────────────┐   │ │
│  │  │  Parse Service  │  │  Generation Service         │   │ │
│  │  │                 │  │                             │   │ │
│  │  │ • Parse natural │  │ • Generate test scripts     │   │ │
│  │  │   language      │  │ • Integrate with LangChain  │   │ │
│  │  │ • Extract test  │  │ • Validate generated code   │   │ │
│  │  │   elements      │  │                             │   │ │
│  │  └─────────────────┘  └─────────────────────────────┘   │ │
│  └─────────────────────────────────────────────────────────┘ │
└─────────────────────────┬───────────────────────────────────┘
                          │
┌─────────────────────────▼───────────────────────────────────┐
│                   LangChain Layer                           │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │                    LLM Integration                      │ │
│  │                                                         │ │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐   │ │
│  │  │ Prompt       │  │ LLM Model    │  │ Output       │   │ │
│  │  │ Templates    │  │ Integration  │  │ Processing   │   │ │
│  │  │              │  │              │  │              │   │ │
│  │  │ • Test case  │  │ • OpenAI     │  │ • JSON       │   │ │
│  │  │   parsing    │  │ • Local LLM  │  │   parsing    │   │ │
│  │  │ • Script     │  │ • API        │  │ • Code       │   │ │
│  │  │   generation │  │   access     │  │   formatting │   │ │
│  │  └──────────────┘  └──────────────┘  └──────────────┘   │ │
│  └─────────────────────────────────────────────────────────┘ │
└─────────────────────────┬───────────────────────────────────┘
                          │
┌─────────────────────────▼───────────────────────────────────┐
│                    Data Layer                               │
│                                                             │
│  ┌──────────────┐  ┌──────────────────┐   │
│  │ Test Cases   │  │ Generated Scripts│   │
│  │ Repository   │  │ Repository       │   │
│  │              │  │                  │   │
│  │ • Store      │  │ • Store          │   │
│  │   test cases │  │   generated      │   │
│  │ • CRUD       │  │   scripts        │   │
│  │   operations │  │ • CRUD           │   │
│  │              │  │   operations     │   │
│  └──────────────┘  └──────────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

## 核心功能模块

### 1. 测试用例解析模块

该模块负责接收自然语言描述的测试用例，并解析出关键测试要素。

**输入参数**:
- `test_case_description`: 自然语言描述的测试用例

**输出结果**:
- 解析后的结构化测试数据
- 包含请求URL、方法、参数、预期结果等信息

### 2. 测试脚本生成模块

该模块基于解析结果，利用LangChain和大语言模型生成自动化测试脚本。

**输入参数**:
- `parsed_test_data`: 解析后的测试数据
- `template_type`: 脚本模板类型（如pytest、unittest等）

**输出结果**:
- 生成的Python测试脚本代码
- 脚本验证结果

### 3. LangChain集成模块

该模块负责与LangChain框架的集成，包括提示词模板管理、模型调用等。

**核心组件**:
- 提示词模板管理器
- 大语言模型接口
- 输出解析器

### 4. 提示词工程设计

本项目采用提示词工程（Prompt Engineering）方法，通过精心设计的提示词模板指导大语言模型生成高质量的测试用例和自动化脚本。目前项目中实现了3个核心提示词模板，每个模板都针对特定的功能模块进行了优化。

#### 4.1 脚本生成提示词模板（create_script_generator_prompt）

该模板用于将结构化的测试用例转换为可执行的Python自动化测试脚本。

**使用场景**：
- 生成符合pytest规范的测试函数
- 创建包含适当断言的测试代码
- 生成可直接执行的Python脚本

**模板特点**：
- 严格规定输出格式，只输出代码不包含解释
- 明确技术要求（PEP8规范、pytest框架、requests库）
- 提供参考样式示例确保输出一致性
- 处理特殊要求如中文字符编码问题

#### 4.2 测试案例生成提示词模板（create_test_case_generator_prompt）

该模板用于根据业务规则文档自动生成详细的测试用例描述。

**使用场景**：
- 基于业务规则生成全面的测试场景
- 自动生成正常流程、异常流程、边界条件测试用例
- 为后续脚本生成提供详细的测试用例描述

**模板特点**：
- 指定AI角色为"专业的测试分析师"
- 要求覆盖多种测试场景类型
- 规范测试用例的结构（测试目标、前置条件、测试步骤、预期结果）

#### 4.3 AI分析提示词模板（create_ai_analysis_prompt）

该模板用于对测试执行结果进行智能分析并生成分析报告。

**使用场景**：
- 分析测试执行的成功/失败情况
- 解读测试输出中的关键信息
- 生成结构化的测试分析报告

**模板特点**：
- 指定AI角色为"专业的测试分析师"
- 要求生成结构化分析报告
- 规定报告包含的关键部分
- 要求以Markdown格式输出便于阅读

#### 4.4 提示词模板使用状态

经检查，项目中的3个提示词工程均处于活跃使用状态：

1. `create_script_generator_prompt`：在生成自动化测试脚本时使用
2. `create_test_case_generator_prompt`：在根据业务规则生成测试案例时使用
3. `create_ai_analysis_prompt`：在AI结果分析功能中使用

这三个提示词模板共同构成了完整的测试自动化流程链，从前端用户交互到后端处理都有相应的调用实现。

## API接口设计

### 1. 转换测试用例接口

```
POST /api/v1/convert-test-case
```

**请求参数**:
```json
{
  "test_case_description": "发送一个正常的GET请求",
  "parser_prompt_template": "可选的解析提示词模板",
  "generator_prompt_template": "可选的生成提示词模板",
  "generation_type": "script或test_cases"
}
```

**响应结果**:
```json
{
  "status": "success",
  "generated_script": "import pytest\nimport requests\n\ndef test_normal_request():\n    url = 'http://example.com/normal_request'\n    response = requests.get(url)\n    assert response.status_code == 200",
  "generated_test_cases": "[{\"test_case\": \"正常GET请求\", \"expected_result\": \"返回200状态码\"}]",
  "metadata": {
    "test_case": "发送一个正常的GET请求"
  }
}
```

### 2. 批量转换接口

```
POST /api/v1/batch-convert
```

**请求参数**:
```json
{
  "test_cases": [
    "发送一个正常的GET请求",
    "发送一个非GET请求，如POST或者PUT"
  ],
  "parser_prompt_template": "可选的解析提示词模板",
  "generator_prompt_template": "可选的生成提示词模板"
}
```

**响应结果**:
```json
{
  "status": "success",
  "results": [
    {
      "test_case": "发送一个正常的GET请求",
      "generated_test_cases": "[{\"test_point\": \"正常GET请求\", \"expected_result\": \"返回200状态码\"}]"
    },
    {
      "test_case": "发送一个非GET请求，如POST或者PUT",
      "generated_test_cases": "[{\"test_point\": \"非GET请求\", \"expected_result\": \"返回405状态码\"}]"
    }
  ]
}
```

## 变量配置管理

### 环境变量配置

```bash
# OpenAI API配置
OPENAI_API_KEY=your_openai_api_key
OPENAI_API_BASE=https://api.openai.com/v1

# 服务配置
HOST=0.0.0.0
PORT=8000
DEBUG=True

# LangChain配置
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langchain_api_key
LANGCHAIN_PROJECT=your_project_name
```

### 配置文件管理

```python
# config.py
import os
from typing import Optional

class Config:
    # OpenAI配置
    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
    OPENAI_API_BASE: str = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
    
    # 服务配置
    HOST: str = os.getenv("HOST", "0.0.0.0")
    PORT: int = int(os.getenv("PORT", "8000"))
    DEBUG: bool = os.getenv("DEBUG", "False").lower() == "true"
    
    # LangChain配置
    LANGCHAIN_TRACING_V2: bool = os.getenv("LANGCHAIN_TRACING_V2", "false").lower() == "true"
    LANGCHAIN_ENDPOINT: str = os.getenv("LANGCHAIN_ENDPOINT", "https://api.smith.langchain.com")
    LANGCHAIN_API_KEY: str = os.getenv("LANGCHAIN_API_KEY", "")
    LANGCHAIN_PROJECT: str = os.getenv("LANGCHAIN_PROJECT", "default")
    
    # 模型配置
    MODEL_NAME: str = os.getenv("MODEL_NAME", "gpt-3.5-turbo")
    MODEL_TEMPERATURE: float = float(os.getenv("MODEL_TEMPERATURE", "0.7"))
```

## 核心代码实现

### 1. LangChain集成服务

```python
# services/langchain_service.py
from langchain_community.chat_models import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from config import Config

class LangChainService:
    def __init__(self):
        self.llm = ChatOpenAI(
            model_name=Config.MODEL_NAME,
            temperature=Config.MODEL_TEMPERATURE,
            openai_api_key=Config.OPENAI_API_KEY,
            openai_api_base=Config.OPENAI_API_BASE
        )
        

        
    def create_script_generator_prompt(self) -> PromptTemplate:
        """创建脚本生成提示词模板"""
        template = """
        你是一个自动化测试工程师，精通的技术栈为 Python pytest requests库。
        请根据以下手工测试用例生成对应的自动化测试脚本：
        {test_case}
        
        要求：
        1. 使用Python语言编写
        2. 使用pytest作为测试框架
        3. 使用requests库发送HTTP请求
        4. 包含适当的断言验证
        5. 代码结构清晰，易于维护
        6. 函数名使用test_前缀，符合pytest规范
        """
        return PromptTemplate.from_template(template)
        
    def parse_test_case(self, context: str, input_text: str) -> str:
        """解析测试用例（已弃用）"""
        # 此方法已弃用，因为test_case_parser模板已被移除
        return "错误：测试用例解析功能已被移除，请使用自定义提示词模板或test_case_generator模板。"
        
    def generate_test_script(self, test_case: str) -> str:
        """生成测试脚本"""
        prompt = self.create_script_generator_prompt()
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke({"test_case": test_case})
```

### 2. 测试用例转换服务

```python
# services/test_case_service.py
from typing import Dict, List
from services.langchain_service import LangChainService

class TestCaseConversionService:
    def __init__(self):
        self.langchain_service = LangChainService()
        
    def convert_single_case(self, test_case_description: str, har_data: str = None, 
                           parser_prompt_template: str = None, generator_prompt_template: str = None,
                           generation_type: str = "script") -> Dict:
        """转换单个文本案例为自动化测试脚本或测试要点"""
        # 注意：parse_test_case功能已弃用，不再处理HAR数据
        # 如果需要处理HAR数据，请使用其他方式
            
        # 根据生成类型调用相应的函数
        if generation_type == "script":
            # 生成自动化测试脚本
            generated_content = self.langchain_service.generate_test_script(
                test_case=test_case_description,
                prompt_template=generator_prompt_template
            )
        else:
            # 生成测试用例
            generated_content = self.langchain_service.generate_test_cases_from_rules(
                business_rules=test_case_description
            )
        
        # 根据生成类型返回不同的字段名
        result = {
            "status": "success",
            "metadata": {
                "test_case": test_case_description
            }
        }
        
        if generation_type == "test_cases":
            result["generated_test_cases"] = generated_content
        else:
            result["generated_script"] = generated_content
            
        return result
        
    def convert_batch_cases(self, test_cases: List[str], har_data: str = None,
                           parser_prompt_template: str = None, generator_prompt_template: str = None) -> Dict:
        """批量转换测试用例为测试要点"""
        results = []
        for test_case in test_cases:
            result = self.convert_single_case(
                test_case_description=test_case,
                har_data=har_data,
                parser_prompt_template=parser_prompt_template,
                generator_prompt_template=generator_prompt_template,
                generation_type="test_cases"
            )
            results.append({
                "test_case": test_case,
                "generated_test_cases": result["generated_test_cases"]
            })
            
        return {
            "status": "success",
            "results": results
        }
```

### 3. FastAPI路由实现

```python
# main.py
from fastapi import FastAPI
from pydantic import BaseModel
from typing import List, Optional
from services.test_case_service import TestCaseConversionService

app = FastAPI(title="AI测试用例转换服务", version="1.0.0")

# 初始化服务
test_case_service = TestCaseConversionService()

class TestCaseRequest(BaseModel):
    test_case_description: str
    har_file_data: Optional[str] = None
    parser_prompt_template: Optional[str] = None
    generator_prompt_template: Optional[str] = None
    generation_type: Optional[str] = "script"

class BatchTestCaseRequest(BaseModel):
    test_cases: List[str]
    har_file_data: Optional[str] = None
    parser_prompt_template: Optional[str] = None
    generator_prompt_template: Optional[str] = None

class TestCaseResponse(BaseModel):
    status: str
    generated_script: Optional[str] = None
    generated_test_cases: Optional[Union[str, List[dict]]] = None
    metadata: dict

class BatchTestCaseResponse(BaseModel):
    status: str
    results: List[dict]

@app.post("/api/v1/convert-test-case", response_model=TestCaseResponse)
async def convert_test_case(request: TestCaseRequest):
    """转换单个测试用例为自动化测试脚本或测试用例"""
    result = test_case_service.convert_single_case(
        test_case_description=request.test_case_description,
        har_data=request.har_file_data,
        parser_prompt_template=request.parser_prompt_template,
        generator_prompt_template=request.generator_prompt_template,
        generation_type=request.generation_type
    )
    return result

@app.post("/api/v1/batch-convert", response_model=BatchTestCaseResponse)
async def batch_convert_test_cases(request: BatchTestCaseRequest):
    """批量转换测试用例为测试用例"""
    result = test_case_service.convert_batch_cases(
        test_cases=request.test_cases,
        har_data=request.har_file_data,
        parser_prompt_template=request.parser_prompt_template,
        generator_prompt_template=request.generator_prompt_template
    )
    return result

@app.get("/health")
async def health_check():
    """健康检查接口"""
    return {"status": "healthy"}

if __name__ == "__main__":
    import uvicorn
    from config import Config
    
    uvicorn.run(
        "main:app",
        host=Config.HOST,
        port=Config.PORT,
        reload=Config.DEBUG
    )
```

## 部署方案

### 本地开发环境部署

1. 安装依赖：
```bash
pip install fastapi uvicorn langchain openai pytest requests python-dotenv
```

2. 配置环境变量：
```bash
export OPENAI_API_KEY=your_openai_api_key
export DEBUG=True
```

3. 启动服务：
```bash
python main.py
```

### 生产环境部署

推荐使用Docker容器化部署：

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["python", "main.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  ai-test-converter:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
    env_file:
      - .env
```

## 测试方案

### 单元测试

```python
# tests/test_langchain_service.py
import pytest
from services.langchain_service import LangChainService

def test_create_script_generator_prompt():
    service = LangChainService()
    prompt = service.create_script_generator_prompt()
    assert prompt is not None
    assert "{test_case}" in prompt.template
```

### 集成测试

```python
# tests/test_test_case_service.py
import pytest
from services.test_case_service import TestCaseConversionService

def test_convert_single_case():
    service = TestCaseConversionService()
    result = service.convert_single_case("发送一个正常的GET请求")
    
    assert result["status"] == "success"
    assert "generated_script" in result
    assert "def test_" in result["generated_script"]
```

## 后续优化方向

1. **模型优化**：训练专门用于测试用例解析的模型
2. **模板扩展**：支持更多测试框架模板（unittest、robot framework等）
3. **错误处理**：增强异常情况的处理能力
4. **性能优化**：实现缓存机制，提高重复请求的响应速度
5. **安全性**：增加输入验证和防护机制
6. **监控**：集成日志和监控系统

---

*本方案基于当前技术调研结果制定，后续实施过程中可能会根据实际情况进行调整优化。*